{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR4qfYrVoO4v"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWVONJxCobPc"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78ZTCIXoof2f",
    "outputId": "cf7c8f82-7aab-49ce-a68c-59b38e957cc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummaryX import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "#Dataset Imports\n",
    "import csv\n",
    "from IPython.display import Audio, display\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ORNHnSFroP0"
   },
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set directory to the Audios folder in MSP dataset\n",
    "AUDIO_ROOT = 'C:\\\\Users\\\\Justin\\\\Documents\\\\idl\\\\2022\\\\Project\\\\Audios_fixed\\\\Audios\\\\'\n",
    "#Set path to labels_consensus in MSP dataset\n",
    "LABELS_DIR = 'C:\\\\Users\\\\Justin\\\\Documents\\\\idl\\\\2022\\\\Project\\\\labels\\\\labels\\\\labels_concensus.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 167814])\n",
      "16000\n",
      "['MSP-PODCAST_0001_0008.wav', 'N', '2.2', '4.0', '2.6', '30', 'Male', 'Test1']\n"
     ]
    }
   ],
   "source": [
    "#Load the directory\n",
    "names = sorted(os.listdir(AUDIO_ROOT))\n",
    "data1 = AUDIO_ROOT + names[0]\n",
    "#torchaudio.load requires you to install some programs if you get 'No audio I/O backend is available' error\n",
    "#https://stackoverflow.com/questions/62543843/cannot-import-torch-audio-no-audio-backend-is-available\n",
    "waveform, sample_rate = torchaudio.load(data1)\n",
    "print(waveform.shape)\n",
    "print(sample_rate)\n",
    "\n",
    "#Load label csv file\n",
    "with open('labels_concensus.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    labels = sorted(list(reader)[1:])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotion Classifier Map (Emotion tag to int for model)\n",
    "#Angry, Sad, Happy, Surprise, Fear, Disgust, Contempt, Neutral, Other\n",
    "EMOMAP = {'A':1, 'S':2, 'H':3, 'U':4, 'F':5, 'D':6, 'C':7, 'N':8, 'O':9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "afd0_vlbJmr_"
   },
   "outputs": [],
   "source": [
    "class MSPDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    #Initialize the dataset based on the recommended split in MSP dataset.\n",
    "    def __init__(self, train = False, valid = False, test1 = False, test2 = False): \n",
    "        \n",
    "        self.audio_dir = AUDIO_ROOT\n",
    "        self.labels_dir = LABELS_DIR\n",
    "        self.audio_names = sorted(names)\n",
    "        self.labels_list = labels\n",
    "        self.EMOMAP = EMOMAP\n",
    "\n",
    "        self.audio = []\n",
    "        self.labels = []\n",
    "        \n",
    "        #What type of dataset are we making\n",
    "        setType = 'Train'\n",
    "        if valid:\n",
    "            setType = 'Validation'\n",
    "        elif test1:\n",
    "            setType = 'Test1'\n",
    "        elif test2:\n",
    "            setType = 'Test2'\n",
    "        print(setType)       \n",
    "        \n",
    "        #Sanitycheck1\n",
    "        assert(len(self.audio_names) == len(self.labels_list))\n",
    "        \n",
    "        for i in tqdm(range(0, len(self.audio_names))):\n",
    "            assert(self.audio_names[i] == self.labels_list[i][0])\n",
    "            if self.labels_list[i][7] != setType or self.labels_list[i][1] == 'X':\n",
    "                continue\n",
    "            #43 Audio files from 1904 podcast seems to be broken. Torchaudio load returns 'no data chunk'\n",
    "            if self.labels_list[i][0].startswith('MSP-PODCAST_1904'):\n",
    "                continue\n",
    "            self.audio.append(self.audio_dir + self.audio_names[i])\n",
    "            self.labels.append(self.EMOMAP[self.labels_list[i][1]])         \n",
    "        \n",
    "        self.length = len(self.audio)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        audio = self.audio[ind]\n",
    "        label = self.labels[ind]\n",
    "        #load audio when getting the item. If we do it in init, computer blue screens.\n",
    "        waveform, sample_rate = torchaudio.load(audio)\n",
    "        return waveform, label\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        batch_audio = [x[0].reshape(-1) for x in batch]\n",
    "        audio_lengths = torch.LongTensor([len(x) for x in batch_audio])\n",
    "        batch_audio = pad_sequence(batch_audio, padding_value=0.0, batch_first = True)\n",
    "        batch_label = [x[1] for x in batch]\n",
    "        \n",
    "        return batch_audio, audio_lengths, torch.tensor(batch_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmuPk9J6L8dz"
   },
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_kG0gU2x4hH",
    "outputId": "95a65754-500e-42ba-99c8-7b90bd6e1ff4",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get me RAMMM!!!! \n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 73042/73042 [00:00<00:00, 1162494.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 73042/73042 [00:00<00:00, 2092453.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 73042/73042 [00:00<00:00, 1786326.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36011\n",
      "6346\n",
      "12371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset objects.\n",
    "train_data = MSPDataset(train = True) \n",
    "val_data = MSPDataset(valid = True) \n",
    "test_data = MSPDataset(test1 = True)\n",
    "\n",
    "print(train_data.__len__())\n",
    "print(val_data.__len__())\n",
    "print(test_data.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set directory to the labelled_emotion folder in NSC dataset\n",
    "NSC_Root = 'C:\\\\Users\\\\Justin\\\\Documents\\\\idl\\\\2022\\\\Project\\\\NSC_part5_labelled_emotion\\\\'\n",
    "#quick way of looping subdirectories. Dataset doesn't have Depressed category.\n",
    "subdirectory = [('Anger\\\\', 0), ('Sad\\\\', 1), ('Happy\\\\', 2), ('Neutral\\\\', 4)]\n",
    "\n",
    "#Normally, we would have train/valid/test but we only have test for now, so we split it outside of our dataset class to make it workable.\n",
    "#I'll update this once we get the full dataset.\n",
    "trainsplit = 70\n",
    "validsplit = 10\n",
    "testsplit = 100 - trainsplit - validsplit\n",
    "\n",
    "train_names = []\n",
    "train_labels = []\n",
    "valid_names = []\n",
    "valid_labels = []\n",
    "test_names = []\n",
    "test_labels = []\n",
    "\n",
    "#Returns lengths\n",
    "for sub, label in subdirectory:\n",
    "    NSCaudios = os.listdir(NSC_Root + sub)\n",
    "    NSClabels = [label]*len(NSCaudios)\n",
    "    n = len(NSCaudios)\n",
    "    trainlen = trainsplit * n //100\n",
    "    validlen = validsplit * n //100\n",
    "    train_names += NSCaudios[0:trainlen]\n",
    "    train_labels += NSClabels[0:trainlen]\n",
    "    valid_names += NSCaudios[trainlen:trainlen+validlen]\n",
    "    valid_labels += NSClabels[trainlen:trainlen+validlen]\n",
    "    test_names += NSCaudios[trainlen+validlen:]\n",
    "    test_labels += NSClabels[trainlen+validlen:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mNSCDataset\u001b[39;00m(torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset):\n\u001b[0;32m      3\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, audio_names, labels, train \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m): \n\u001b[0;32m      4\u001b[0m         \u001b[39m#Sanitycheck1\u001b[39;00m\n\u001b[0;32m      5\u001b[0m         \u001b[39massert\u001b[39;00m(\u001b[39mlen\u001b[39m(audio_names) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(labels))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class NSCDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, audio_names, labels, train = False): \n",
    "        #Sanitycheck1\n",
    "        assert(len(audio_names) == len(labels))\n",
    "        self.labels = labels\n",
    "        self.audio = audio_names\n",
    "        self.length = len(labels)\n",
    "        self.Map = {0:'Anger\\\\', 1:'Sad\\\\', 2:'Happy\\\\', 4:'Neutral\\\\'}\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        audio = self.audio[ind]\n",
    "        label = self.labels[ind]\n",
    "        #load audio when getting the item. If we do it in init, computer blue screens.\n",
    "        waveform, sample_rate = torchaudio.load(NSC_Root + self.Map[label] + audio)\n",
    "        return waveform, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get me RAMMM!!!! \n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSC_train_data = NSCDataset(train_names, train_labels)\n",
    "NSC_valid_data = NSCDataset(valid_names, valid_labels)\n",
    "NSC_test_Data = NSCDataset(test_names, test_labels)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UR4qfYrVoO4v",
    "gg3-yJ8tok34",
    "R9v5ewZDMpYA",
    "Ly4mjUUUuJhy",
    "HLad4pChcuvX",
    "tUThsowyQdN7",
    "IBwunYpyugFg",
    "kH0RAbCaMl9a",
    "qpYExu4vT4_g",
    "MY69hgxUXhTI",
    "M2H4EEj-sD32"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "50a168d2e944e50d64023c982abdec6febc400ad89db390dba97250ae813c14d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
