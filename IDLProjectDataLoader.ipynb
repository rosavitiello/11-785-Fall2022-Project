{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR4qfYrVoO4v"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWVONJxCobPc"
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78ZTCIXoof2f",
    "outputId": "cf7c8f82-7aab-49ce-a68c-59b38e957cc7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummaryX import summary\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "#Dataset Imports\n",
    "import csv\n",
    "from IPython.display import Audio, display\n",
    "import torchaudio\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ORNHnSFroP0"
   },
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set directory to the Audios folder in MSP dataset\n",
    "AUDIO_ROOT = 'C:\\\\Users\\\\Justin\\\\Documents\\\\idl\\\\2022\\\\Project\\\\Audios_fixed\\\\Audios\\\\'\n",
    "#Set path to labels_consensus in MSP dataset\n",
    "LABELS_DIR = 'C:\\\\Users\\\\Justin\\\\Documents\\\\idl\\\\2022\\\\Project\\\\labels\\\\labels\\\\labels_concensus.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 167814])\n",
      "16000\n",
      "['MSP-PODCAST_0001_0008.wav', 'N', '2.2', '4.0', '2.6', '30', 'Male', 'Test1']\n"
     ]
    }
   ],
   "source": [
    "#Load the directory\n",
    "names = sorted(os.listdir(AUDIO_ROOT))\n",
    "data1 = AUDIO_ROOT + names[0]\n",
    "#torchaudio.load requires you to install some programs if you get 'No audio I/O backend is available' error\n",
    "#https://stackoverflow.com/questions/62543843/cannot-import-torch-audio-no-audio-backend-is-available\n",
    "waveform, sample_rate = torchaudio.load(data1)\n",
    "print(waveform.shape)\n",
    "print(sample_rate)\n",
    "\n",
    "#Load label csv file\n",
    "with open('labels_concensus.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    labels = sorted(list(reader)[1:])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emotion Classifier Map (Emotion tag to int for model)\n",
    "#Angry, Sad, Happy, Surprise, Fear, Disgust, Contempt, Neutral, Other\n",
    "EMOMAP = {'A':1, 'S':2, 'H':3, 'U':4, 'F':5, 'D':6, 'C':7, 'N':8, 'O':9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "afd0_vlbJmr_"
   },
   "outputs": [],
   "source": [
    "class MSPDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    #Initialize the dataset based on the recommended split in MSP dataset.\n",
    "    def __init__(self, train = False, valid = False, test1 = False, test2 = False): \n",
    "        \n",
    "        self.audio_dir = AUDIO_ROOT\n",
    "        self.labels_dir = LABELS_DIR\n",
    "        self.audio_names = sorted(names)\n",
    "        self.labels_list = labels\n",
    "        self.EMOMAP = EMOMAP\n",
    "\n",
    "        self.audio = []\n",
    "        self.labels = []\n",
    "        \n",
    "        #What type of dataset are we making\n",
    "        setType = 'Train'\n",
    "        if valid:\n",
    "            setType = 'Validation'\n",
    "        elif test1:\n",
    "            setType = 'Test1'\n",
    "        elif test2:\n",
    "            setType = 'Test2'\n",
    "        print(setType)       \n",
    "        \n",
    "        #Sanitycheck1\n",
    "        assert(len(self.audio_names) == len(self.labels_list))\n",
    "        \n",
    "        for i in tqdm(range(0, len(self.audio_names))):\n",
    "            assert(self.audio_names[i] == self.labels_list[i][0])\n",
    "            if self.labels_list[i][7] != setType or self.labels_list[i][1] == 'X':\n",
    "                continue\n",
    "            #43 Audio files from 1904 podcast seems to be broken. Torchaudio load returns 'no data chunk'\n",
    "            if self.labels_list[i][0].startswith('MSP-PODCAST_1904'):\n",
    "                continue\n",
    "            self.audio.append(self.audio_dir + self.audio_names[i])\n",
    "            self.labels.append(self.EMOMAP[self.labels_list[i][1]])         \n",
    "        \n",
    "        self.length = len(self.audio)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        audio = self.audio[ind]\n",
    "        label = self.labels[ind]\n",
    "        #load audio when getting the item. If we do it in init, computer blue screens.\n",
    "        waveform, sample_rate = torchaudio.load(audio)\n",
    "        return waveform, label\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        batch_audio = [x[0].reshape(-1) for x in batch]\n",
    "        audio_lengths = torch.LongTensor([len(x) for x in batch_audio])\n",
    "        batch_audio = pad_sequence(batch_audio, padding_value=0.0, batch_first = True)\n",
    "        batch_label = [x[1] for x in batch]\n",
    "        \n",
    "        return batch_audio, audio_lengths, torch.tensor(batch_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmuPk9J6L8dz"
   },
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3_kG0gU2x4hH",
    "outputId": "95a65754-500e-42ba-99c8-7b90bd6e1ff4",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get me RAMMM!!!! \n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 73042/73042 [00:00<00:00, 1162494.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 73042/73042 [00:00<00:00, 2092453.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 73042/73042 [00:00<00:00, 1786326.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36011\n",
      "6346\n",
      "12371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset objects.\n",
    "train_data = MSPDataset(train = True) \n",
    "val_data = MSPDataset(valid = True) \n",
    "test_data = MSPDataset(test1 = True)\n",
    "\n",
    "print(train_data.__len__())\n",
    "print(val_data.__len__())\n",
    "print(test_data.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set directory to the labelled_emotion folder in NSC dataset\n",
    "NSC_Root = 'C:\\\\Users\\\\Justin\\\\Documents\\\\idl\\\\2022\\\\Project\\\\NSC_part5_labelled_emotion\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSCDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self): \n",
    "        \n",
    "        self.audio_dir = NSC_Root\n",
    "        #quick way of looping subdirectories. Dataset only has 4 categories. \n",
    "        self.subdirectory = [('Anger\\\\', 0), ('Sad\\\\', 1), ('Happy\\\\', 2), ('Neutral\\\\', 4)]\n",
    "        self.audio = []\n",
    "        self.labels = []\n",
    "        for sub, label in subdirectory:\n",
    "            NSCaudios = os.listdir(NSC_Root + sub)\n",
    "            self.audio += [NSC_Root + sub + x for x in NSCaudios]\n",
    "            self.labels += [label]*len(NSCaudios) \n",
    "        #Sanitycheck1\n",
    "        assert(len(self.audio) == len(self.labels))\n",
    "        self.length = len(self.audio)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        audio = self.audio[ind]\n",
    "        label = self.labels[ind]\n",
    "        #load audio when getting the item. If we do it in init, computer blue screens.\n",
    "        waveform, sample_rate = torchaudio.load(audio)\n",
    "        waveform = processor(waveform, sampling_rate = 16000,padding=True, device = device)\n",
    "        # waveform = waveform.to(device)\n",
    "        # label = label.to(device)\n",
    "        waveform['labels'] = label\n",
    "\n",
    "        return waveform\n",
    "        #return waveform, label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get me RAMMM!!!! \n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works with hugging face dataset.\n",
    "NSCTest = NSCDataset()\n",
    "NSCTest[0]\n",
    "NSCtest_dataset = Dataset.from_list(NSCTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified sort to train/test splits. Requires encoding the columns to classes first.\n",
    "NSCtest_dataset2 = NSCtest_dataset.class_encode_column('labels')\n",
    "NSCtest_dataset2.train_test_split(test_size = 0.1, stratify_by_column = 'labels')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "UR4qfYrVoO4v",
    "gg3-yJ8tok34",
    "R9v5ewZDMpYA",
    "Ly4mjUUUuJhy",
    "HLad4pChcuvX",
    "tUThsowyQdN7",
    "IBwunYpyugFg",
    "kH0RAbCaMl9a",
    "qpYExu4vT4_g",
    "MY69hgxUXhTI",
    "M2H4EEj-sD32"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "50a168d2e944e50d64023c982abdec6febc400ad89db390dba97250ae813c14d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
